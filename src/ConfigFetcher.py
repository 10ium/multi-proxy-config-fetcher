import re
import os
import time
import json
import logging
import socket 
import requests
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional, Set, Tuple, Any 
from bs4 import BeautifulSoup
import base64 

import concurrent.futures # Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ Ù‡Ù…Ø²Ù…Ø§Ù†
import threading # Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…Ø´ØªØ±Ú© Ø¯Ø± Ø­Ø§Ù„Øª Ù‡Ù…Ø²Ù…Ø§Ù†

from config import ProxyConfig, ChannelConfig
from config_validator import ConfigValidator
from user_settings import SOURCE_URLS 

# Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ (Ø§Ø² config.py Ø§Ø±Ø« Ù…ÛŒâ€ŒØ¨Ø±Ø¯ ÛŒØ§ Ø§ÛŒÙ†Ø¬Ø§ ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
logging.basicConfig(
    level=logging.INFO, # Ø³Ø·Ø­ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ: INFO. Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ DEBUG Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('proxy_fetcher.log'), # Ù„Ø§Ú¯ Ø¯Ø± ÙØ§ÛŒÙ„
        logging.StreamHandler() # Ù„Ø§Ú¯ Ø¯Ø± Ú©Ù†Ø³ÙˆÙ„
    ]
)
logger = logging.getLogger(__name__)

class ConfigFetcher:
    """
    Ú©Ù„Ø§Ø³ ConfigFetcher Ù…Ø³Ø¦ÙˆÙ„ ÙˆØ§Ú©Ø´ÛŒØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ ØºÙ†ÛŒâ€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø§Ú©Ø³ÛŒ Ø§Ø³Øª.
    Ù‡Ù…Ú†Ù†ÛŒÙ† Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ØŒ Smart Retry Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø¹Ù‡Ø¯Ù‡ Ø¯Ø§Ø±Ø¯.
    """
    def __init__(self, config: ProxyConfig):
        """
        Ø³Ø§Ø²Ù†Ø¯Ù‡ Ú©Ù„Ø§Ø³ ConfigFetcher.
        """
        logger.info("Ø¯Ø± Ø­Ø§Ù„ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ConfigFetcher...")
        self.config = config
        self.validator = ConfigValidator()
        self.protocol_counts: Dict[str, int] = {p: 0 for p in config.SUPPORTED_PROTOCOLS}
        self.seen_configs: Set[str] = set() 
        self.channel_protocol_counts: Dict[str, Dict[str, int]] = {} 
        self.session = requests.Session() 
        self.session.headers.update(config.HEADERS) 

        self.ip_location_cache: Dict[str, Tuple[str, str]] = {} 

        self._lock = threading.Lock() 

        self.retry_intervals = [
            timedelta(days=0),
            timedelta(days=3),
            timedelta(weeks=1),
            timedelta(days=30),
            timedelta(days=90),
            timedelta(days=240)
        ]
        self.max_retry_level = len(self.retry_intervals) - 1 
        
        self.initial_user_settings_urls: Set[str] = {self.config._normalize_url(url) for url in SOURCE_URLS}
        self.previous_stats_urls: Set[str] = set()
        self._load_previous_stats_urls()
        
        logger.info("Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ConfigFetcher Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

    def _load_previous_stats_urls(self):
        """
        Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ URLÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø§Ø² channel_stats.json Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯.
        """
        stats_file_path = os.path.join(self.config.OUTPUT_DIR, 'channel_stats.json')
        if os.path.exists(stats_file_path):
            try:
                with open(stats_file_path, 'r', encoding='utf-8') as f:
                    stats_data = json.load(f)
                for channel_data in stats_data.get('channels', []):
                    try:
                        self.previous_stats_urls.add(self.config._normalize_url(channel_data['url']))
                    except ValueError as e:
                        logger.warning(f"URL Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¯Ø± stats.json Ù‚Ø¨Ù„ÛŒ ÛŒØ§ÙØª Ø´Ø¯ Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: {channel_data.get('url', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')} - {str(e)}")
                logger.debug(f"{len(self.previous_stats_urls)} URL Ø§Ø² stats.json Ù‚Ø¨Ù„ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
            except Exception as e:
                logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ URLÙ‡Ø§ Ø§Ø² stats.json Ù‚Ø¨Ù„ÛŒ: {str(e)}")

    def _get_location_from_ip_api(self, ip: str) -> Tuple[str, str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø§Ø² ip-api.com"""
        try:
            response = requests.get(f'http://ip-api.com/json/{ip}', headers=self.session.headers, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('status') == 'success' and data.get('countryCode'):
                    return data['countryCode'].lower(), data['country']
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± API ip-api.com Ø¨Ø±Ø§ÛŒ IP {ip}: {str(e)}")
        return '', ''

    def _get_location_from_ipapi_co(self, ip: str) -> Tuple[str, str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø§Ø² ipapi.co"""
        try:
            response = requests.get(f'https://ipapi.co/{ip}/json/', headers=self.session.headers, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('country_code') and data.get('country_name'):
                    return data['country_code'].lower(), data['country_name']
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± API ipapi.co Ø¨Ø±Ø§ÛŒ IP {ip}: {str(e)}")
        return '', ''

    def _get_location_from_ipwhois(self, ip: str) -> Tuple[str, str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø§Ø² ipwhois.app"""
        try:
            response = requests.get(f'https://ipwhois.app/json/{ip}', headers=self.session.headers, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('country_code') and data.get('country'):
                    return data['country_code'].lower(), data['country']
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± API ipwhois.app Ø¨Ø±Ø§ÛŒ IP {ip}: {str(e)}")
        return '', ''

    def _get_location_from_ipdata(self, ip: str) -> Tuple[str, str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø§Ø² api.ipdata.co (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ù„ÛŒØ¯ API ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø§Ø±Ø¯)"""
        try:
            response = requests.get(f'https://api.ipdata.co/{ip}?api-key=test', headers=self.session.headers, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('country_code') and data.get('country_name'):
                    return data['country_code'].lower(), data['country_name']
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± API ipdata.co Ø¨Ø±Ø§ÛŒ IP {ip}: {str(e)}")
        return '', ''

    def _get_location_from_abstractapi(self, ip: str) -> Tuple[str, str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ Ø§Ø² ipgeolocation.abstractapi.com (Ù†ÛŒØ§Ø² Ø¨Ù‡ Ú©Ù„ÛŒØ¯ API ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø§Ø±Ø¯)"""
        try:
            response = requests.get(f'https://ipgeolocation.abstractapi.com/v1/?api_key=test', headers=self.session.headers, timeout=5)
            if response.status_code == 200:
                data = response.json()
                if data.get('country_code') and data.get('country'):
                    return data['country_code'].lower(), data['country']
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± API abstractapi.com Ø¨Ø±Ø§ÛŒ IP {ip}: {str(e)}")
        return '', ''

    def get_location(self, address: str) -> Tuple[str, str]:
        """
        Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¬ØºØ±Ø§ÙÛŒØ§ÛŒÛŒ (Ù¾Ø±Ú†Ù… Ùˆ Ù†Ø§Ù… Ú©Ø´ÙˆØ±) Ø±Ø§ Ø§Ø² ÛŒÚ© Ø¢Ø¯Ø±Ø³ (Ø¯Ø§Ù…Ù†Ù‡/IP) Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ø§Ø² Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        if address == "162.159.192.1": # Cloudflare Anycast IP
             logger.debug(f"Ø¢Ø¯Ø±Ø³ '{address}' Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Cloudflare Anycast Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ÙˆÙ‚Ø¹ÛŒØª Ù¾ÛŒØ´â€ŒÙØ±Ø¶.")
             return "ğŸ‡ºğŸ‡¸", "Cloudflare"

        try:
            ip = socket.gethostbyname(address)
            
            with self._lock: 
                if ip in self.ip_location_cache:
                    logger.debug(f"Ù…ÙˆÙ‚Ø¹ÛŒØª IP '{ip}' Ø§Ø² Ú©Ø´ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯.")
                    return self.ip_location_cache[ip]

            apis = [
                self._get_location_from_ip_api,
                self._get_location_from_ipapi_co,
                self._get_location_from_ipwhois,
                self._get_location_from_ipdata,
                self._get_location_from_abstractapi
            ]
            
            for api_func in apis:
                country_code, country = api_func(ip)
                if country_code and country and len(country_code) == 2:
                    flag = ''.join(chr(ord('ğŸ‡¦') + ord(c.upper()) - ord('A')) for c in country_code)
                    with self._lock: 
                        self.ip_location_cache[ip] = (flag, country)
                    logger.debug(f"Ù…ÙˆÙ‚Ø¹ÛŒØª IP '{ip}' Ø§Ø² API {api_func.__name__} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {flag} {country}")
                    return flag, country
                
        except socket.gaierror:
            logger.debug(f"Ù†Ø§Ù… Ù…ÛŒØ²Ø¨Ø§Ù† Ù‚Ø§Ø¨Ù„ Ø­Ù„ Ù†ÛŒØ³Øª: '{address}'. Ù…ÙˆÙ‚Ø¹ÛŒØª 'Ù†Ø§Ù…Ø´Ø®Øµ' Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.") 
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ '{address}': {str(e)}")
            
        with self._lock: 
            self.ip_location_cache[address] = ("ğŸ³ï¸", "Unknown") 
        return "ğŸ³ï¸", "Unknown"


    def extract_config(self, text: str, start_index: int, protocol: str) -> Optional[str]:
        """
        ØªÙ„Ø§Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Øµ (Ø¨Ø§ Ù¾Ø±ÙˆØªÚ©Ù„ Ù…Ø´Ø®Øµ) Ø§Ø² ÛŒÚ© Ù…ØªÙ† Ø¨Ø²Ø±Ú¯.
        """
        try:
            remaining_text = text[start_index:]
            configs = self.validator.split_configs(remaining_text)
            
            for config_item in configs:
                if config_item.startswith(protocol):
                    clean_config = self.validator.clean_config(config_item)
                    if self.validator.validate_protocol_config(clean_config, protocol):
                        return clean_config
            return None
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± extract_config: {str(e)}")
            return None

    def fetch_with_retry(self, url: str) -> Optional[requests.Response]:
        """
        ÙˆØ§Ú©Ø´ÛŒ URL Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ùˆ ØªØ£Ø®ÛŒØ± Ø§ÙØ²Ø§ÛŒØ´ÛŒ.
        """
        backoff = 1
        for attempt in range(self.config.MAX_RETRIES):
            try:
                # Ù„Ø§Ú¯ INFO Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ ØªÙ„Ø§Ø´ ÙˆØ§Ú©Ø´ÛŒØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ù„Ø²ÙˆÙ… Ø¨Ù‡ DEBUG ØªØºÛŒÛŒØ± ÛŒØ§Ø¨Ø¯.
                logger.debug(f"Ø¯Ø± Ø­Ø§Ù„ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ '{url}' (ØªÙ„Ø§Ø´ {attempt + 1}/{self.config.MAX_RETRIES})")
                response = self.session.get(url, timeout=self.config.REQUEST_TIMEOUT)
                response.raise_for_status() 
                return response
            except requests.RequestException as e:
                if attempt == self.config.MAX_RETRIES - 1:
                    logger.error(f"ÙˆØ§Ú©Ø´ÛŒ '{url}' Ù¾Ø³ Ø§Ø² {self.config.MAX_RETRIES} ØªÙ„Ø§Ø´ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {str(e)}")
                    return None
                wait_time = min(self.config.RETRY_DELAY * backoff, 60)
                logger.warning(f"ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ '{url}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± {wait_time} Ø«Ø§Ù†ÛŒÙ‡: {str(e)}")
                time.sleep(wait_time)
                backoff *= 2 
        return None

    def fetch_ssconf_configs(self, url: str) -> List[str]:
        """
        ÙˆØ§Ú©Ø´ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø§Ø² URLÙ‡Ø§ÛŒ ssconf:// Ø¨Ø§ ØªØ¨Ø¯ÛŒÙ„ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ HTTPS Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§.
        """
        https_url = self.validator.convert_ssconf_to_https(url)
        configs = []
        logger.debug(f"Ø¯Ø± Ø­Ø§Ù„ ÙˆØ§Ú©Ø´ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ ssconf Ø§Ø²: '{https_url}'") # ØªØºÛŒÛŒØ± Ø³Ø·Ø­ Ø¨Ù‡ DEBUG
        
        response = self.fetch_with_retry(https_url)
        if response and response.text.strip():
            text = response.text.strip()
            decoded_text = self.check_and_decode_base64(text)
            if decoded_text:
                logger.debug(f"Ù…Ø­ØªÙˆØ§ÛŒ ssconf Ø§Ø² Base64 Ø¯ÛŒÚ©Ø¯ Ø´Ø¯.")
                text = decoded_text
            
            found_configs = self.validator.split_configs(text)
            configs.extend(found_configs)
            logger.debug(f"{len(found_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² ssconf '{https_url}' ÛŒØ§ÙØª Ø´Ø¯.") # ØªØºÛŒÛŒØ± Ø³Ø·Ø­ Ø¨Ù‡ DEBUG
        else:
            logger.warning(f"Ù‡ÛŒÚ† Ù…Ø­ØªÙˆØ§ÛŒÛŒ Ø§Ø² ssconf '{https_url}' Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯.")
            
        return configs

    def check_and_decode_base64(self, text: str) -> Optional[str]:
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¢ÛŒØ§ Ú©Ù„ Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ Base64 Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù…Ø«Ø¨Øª Ø¨ÙˆØ¯Ù†ØŒ Ø¢Ù† Ø±Ø§ Ø¯ÛŒÚ©Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        try:
            decoded_text = self.validator.decode_base64_text(text)
            if decoded_text:
                if any(p in decoded_text for p in self.config.SUPPORTED_PROTOCOLS):
                    logger.debug(f"Ù…ØªÙ† Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Base64 Ø¯ÛŒÚ©Ø¯ Ø´Ø¯ Ùˆ Ø´Ø§Ù…Ù„ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª.")
                    return decoded_text
            logger.debug(f"Ù…ØªÙ† Base64 Ù†ÛŒØ³Øª ÛŒØ§ Ø´Ø§Ù…Ù„ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ù†ÛŒØ³Øª.")
            return None
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯ÛŒÚ©Ø¯ Ú©Ø±Ø¯Ù† Base64: {str(e)}")
            return None

    def add_new_telegram_channel(self, new_channel_url: str):
        """
        ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø¬Ø¯ÛŒØ¯ Ø±Ø§ (Ø¯Ø± ØµÙˆØ±Øª Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯) Ø¨Ù‡ Ù„ÛŒØ³Øª Ù…Ù†Ø§Ø¨Ø¹ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        is_new_channel = True
        with self._lock: 
            for existing_channel in self.config.SOURCE_URLS:
                if self.config._normalize_url(existing_channel.url) == self.config._normalize_url(new_channel_url):
                    is_new_channel = False
                    break
            
            if is_new_channel:
                try:
                    new_channel_config = ChannelConfig(url=new_channel_url)
                    self.config.SOURCE_URLS.append(new_channel_config)
                    logger.info(f"Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø¬Ø¯ÛŒØ¯ Ø¨Ù‡ ØµÙˆØ±Øª Ù¾ÙˆÛŒØ§ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯: '{new_channel_url}'.")
                except ValueError as e:
                    logger.warning(f"URL Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ù¾ÛŒØ¯Ø§ Ø´Ø¯ Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: '{new_channel_url}' - {e}")


    def fetch_configs_from_source(self, channel: ChannelConfig) -> List[Dict[str, str]]:
        """
        ÙˆØ§Ú©Ø´ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø§Ø² ÛŒÚ© Ú©Ø§Ù†Ø§Ù„ Ù…Ù†Ø¨Ø¹ Ù…Ø´Ø®Øµ (ØªÙ„Ú¯Ø±Ø§Ù… ÛŒØ§ ÙˆØ¨â€ŒØ³Ø§ÛŒØª).
        Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§: Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø² Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ùˆ Ø§Ø² Ù…Ø´Ø®ØµØ§Øª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§.
        """
        # Ù„Ø§Ú¯ INFO Ø´Ø±ÙˆØ¹ ÙˆØ§Ú©Ø´ÛŒ Ø§Ø² Ù…Ù†Ø¨Ø¹ Ø¯Ø± fetch_all_configs Ø§ØªÙØ§Ù‚ Ù…ÛŒâ€ŒØ§ÙØªØ¯
        current_channel_valid_processed_configs: List[Dict[str, str]] = []
        
        channel.metrics.total_configs = 0
        channel.metrics.valid_configs = 0
        channel.metrics.unique_configs = 0
        channel.metrics.protocol_counts = {p: 0 for p in self.config.SUPPORTED_PROTOCOLS}
        
        start_time = time.time()
        
        if channel.url.startswith('ssconf://'):
            logger.debug(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø¨Ø¹ ssconf:// Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯.")
            raw_ssconf_configs = self.fetch_ssconf_configs(channel.url)
            channel.metrics.total_configs += len(raw_ssconf_configs)
            logger.debug(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ {len(raw_ssconf_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ø§Ø² '{channel.url}'.")
            for raw_cfg in raw_ssconf_configs:
                processed_cfg_dict = self.process_config(raw_cfg, channel)
                if processed_cfg_dict:
                    current_channel_valid_processed_configs.append(processed_cfg_dict)
            
            if current_channel_valid_processed_configs:
                response_time = time.time() - start_time
                self.config.update_channel_stats(channel, True, response_time)
                channel.retry_level = 0
                channel.next_check_time = None
                # Ù„Ø§Ú¯ INFO Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø­Ø°Ù Ø´ÙˆØ¯ ÛŒØ§ Ø¨Ù‡ DEBUG ØªØºÛŒÛŒØ± ÛŒØ§Ø¨Ø¯ Ø²ÛŒØ±Ø§ fetch_all_configs Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.
                # logger.info(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª {len(current_channel_valid_processed_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø§Ø¯. Ø³Ø·Ø­ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø´Ø¯.")
            else:
                self.config.update_channel_stats(channel, False)
                channel.retry_level = min(channel.retry_level + 1, self.max_retry_level)
                channel.next_check_time = datetime.now(timezone.utc) + self.retry_intervals[channel.retry_level]
                # logger.warning(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù†Ø¯Ø§Ø´Øª. Ø³Ø·Ø­ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ù‡ {channel.retry_level} Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØª. Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø±: {channel.next_check_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")

            return current_channel_valid_processed_configs

        response = self.fetch_with_retry(channel.url)
        if not response:
            self.config.update_channel_stats(channel, False)
            channel.retry_level = min(channel.retry_level + 1, self.max_retry_level)
            channel.next_check_time = datetime.now(timezone.utc) + self.retry_intervals[channel.retry_level]
            # logger.warning(f"ÙˆØ§Ú©Ø´ÛŒ Ø§Ø² Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ø³Ø·Ø­ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ù‡ {channel.retry_level} Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØª. Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø±: {channel.next_check_time.strftime('%Y-%m-%d %H:%M:%S UTC')}")
            return current_channel_valid_processed_configs

        response_time = time.time() - start_time
        
        if channel.is_telegram:
            logger.debug(f"Ø¯Ø± Ø­Ø§Ù„ ØªØ¬Ø²ÛŒÙ‡ Ù…Ø­ØªÙˆØ§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„: '{channel.url}'.")
            soup = BeautifulSoup(response.text, 'html.parser')
            messages = soup.find_all('div', class_='tgme_widget_message_text')
            
            sorted_messages = sorted(
                messages,
                key=lambda message: self.extract_date_from_message(message) or datetime.min.replace(tzinfo=timezone.utc),
                reverse=True
            )
            logger.debug(f"{len(messages)} Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù… ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§...")
            
            for message_div in sorted_messages:
                if not message_div or not message_div.text:
                    logger.debug("Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù… Ø®Ø§Ù„ÛŒ ÛŒØ§ Ø¨Ø¯ÙˆÙ† Ù…ØªÙ†ØŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
                    continue
                
                message_date = self.extract_date_from_message(message_div)
                if not self.is_config_valid(message_div.text, message_date):
                    logger.debug(f"Ù¾ÛŒØ§Ù… Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ù†Ø§Ù…Ø¹ØªØ¨Ø± (ØªØ§Ø±ÛŒØ®: {message_date}) Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯. Ù…Ø­ØªÙˆØ§: '{message_div.text[:min(len(message_div.text), 50)]}...'.")
                    continue
                
                # --- Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø² Ù¾ÛŒØ§Ù… (Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ø´Ù†â€ŒÙ‡Ø§) ---
                links_and_mentions = message_div.find_all('a', href=True)
                for item in links_and_mentions:
                    href_url = item['href']
                    logger.debug(f"Ù„ÛŒÙ†Ú© ÛŒØ§ÙØª Ø´Ø¯ Ø¯Ø± Ù¾ÛŒØ§Ù…: '{href_url}'")
                    
                    # 1. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² URL Ù„ÛŒÙ†Ú©
                    extracted_from_link = self.validator.split_configs(href_url)
                    channel.metrics.total_configs += len(extracted_from_link)
                    for cfg_from_link in extracted_from_link:
                        processed_cfg_dict = self.process_config(cfg_from_link, channel)
                        if processed_cfg_dict:
                            current_channel_valid_processed_configs.append(processed_cfg_dict)
                            logger.debug(f"Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² Ù„ÛŒÙ†Ú© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {processed_cfg_dict['protocol']}.")
                    
                    # 2. Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ href_url ÛŒÚ© Ù„ÛŒÙ†Ú© Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ Ø§ÙØ²ÙˆØ¯Ù† Ù¾ÙˆÛŒØ§
                    match_s = re.match(r'https?://t\.me/s/([a-zA-Z0-9_]+)', href_url)
                    match_direct = re.match(r'https?://t\.me/([a-zA-Z0-9_]+)', href_url)
                    
                    channel_name = None
                    if match_s:
                        channel_name = match_s.group(1)
                    elif match_direct:
                        channel_name = match_direct.group(1)
                    
                    if channel_name:
                        new_channel_url = f"https://t.me/s/{channel_name}"
                        self.add_new_telegram_channel(new_channel_url)
                # --- Ù¾Ø§ÛŒØ§Ù† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø§Ø² Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ø´Ù†â€ŒÙ‡Ø§ ---

                # --- Ù…Ù†Ø·Ù‚ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ Ù¾ÛŒØ§Ù… ---
                text_content = message_div.text
                logger.debug(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ Ù…ØªÙ†ÛŒ Ù¾ÛŒØ§Ù…: '{text_content[:min(len(text_content), 100)]}...'")
                
                decoded_full_text = self.check_and_decode_base64(text_content)
                if decoded_full_text:
                    raw_configs_from_decoded = self.validator.split_configs(decoded_full_text)
                    channel.metrics.total_configs += len(raw_configs_from_decoded)
                    for raw_cfg in raw_configs_from_decoded:
                        processed_cfg_dict = self.process_config(raw_cfg, channel)
                        if processed_cfg_dict:
                            current_channel_valid_processed_configs.append(processed_cfg_dict)
                            logger.debug(f"Ú©Ø§Ù†ÙÛŒÚ¯ Ø¯ÛŒÚ©Ø¯ Ø´Ø¯Ù‡ Ø§Ø² Ù…ØªÙ† Ù¾ÛŒØ§Ù…: {processed_cfg_dict['protocol']}.")
                else:
                    raw_configs_from_text = self.validator.split_configs(text_content)
                    channel.metrics.total_configs += len(raw_configs_from_text)
                    for raw_cfg in raw_configs_from_text:
                        processed_cfg_dict = self.process_config(raw_cfg, channel)
                        if processed_cfg_dict:
                            current_channel_valid_processed_configs.append(processed_cfg_dict)
                            logger.debug(f"Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø² Ù…ØªÙ† Ù¾ÛŒØ§Ù…: {processed_cfg_dict['protocol']}.")

        else: # Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ØªÙ„Ú¯Ø±Ø§Ù… (ØµÙØ­Ø§Øª ÙˆØ¨ Ø¹Ù…ÙˆÙ…ÛŒ)
            logger.debug(f"Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„: '{channel.url}'.")
            text_content = response.text
            decoded_full_text = self.check_and_decode_base64(text_content)
            if decoded_full_text:
                raw_configs_from_decoded = self.validator.split_configs(decoded_full_text)
                channel.metrics.total_configs += len(raw_configs_from_decoded)
                for raw_cfg in raw_configs_from_decoded:
                    processed_cfg_dict = self.process_config(raw_cfg, channel)
                    if processed_cfg_dict:
                        current_channel_valid_processed_configs.append(processed_cfg_dict)
            else:
                raw_configs_from_web = self.validator.split_configs(text_content)
                channel.metrics.total_configs += len(raw_configs_from_web)
                for raw_cfg in raw_configs_from_web:
                    processed_cfg_dict = self.process_config(raw_cfg, channel)
                    if processed_cfg_dict:
                        current_channel_valid_processed_configs.append(processed_cfg_dict)

        # Ù…Ù†Ø·Ù‚ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ retry_level Ùˆ next_check_time
        if len(current_channel_valid_processed_configs) >= self.config.MIN_CONFIGS_PER_CHANNEL:
            self.config.update_channel_stats(channel, True, response_time)
            self.config.adjust_protocol_limits(channel)
            channel.retry_level = 0
            channel.next_check_time = None
            # Ù„Ø§Ú¯ INFO Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø­Ø°Ù Ø´ÙˆØ¯ ÛŒØ§ Ø¨Ù‡ DEBUG ØªØºÛŒÛŒØ± ÛŒØ§Ø¨Ø¯
            # logger.info(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª {len(current_channel_valid_processed_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø± Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ø§Ø¯. Ø³Ø·Ø­ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø´Ø¯.")
        else:
            self.config.update_channel_stats(channel, False)
            channel.retry_level = min(channel.retry_level + 1, self.max_retry_level)
            channel.next_check_time = datetime.now(timezone.utc) + self.retry_intervals[channel.retry_level]
            # Ù„Ø§Ú¯ WARNING Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø­Ø°Ù Ø´ÙˆØ¯ ÛŒØ§ Ø¨Ù‡ DEBUG ØªØºÛŒÛŒØ± ÛŒØ§Ø¨Ø¯
            # logger.warning(f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§ÙÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ Ø¯Ø± Ú©Ø§Ù†Ø§Ù„ '{channel.url}' ÛŒØ§ÙØª Ù†Ø´Ø¯: {len(current_channel_valid_processed_configs)} Ú©Ø§Ù†ÙÛŒÚ¯. Ø³Ø·Ø­ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ù‡ {channel.retry_level} Ø§ÙØ²Ø§ÛŒØ´ ÛŒØ§ÙØª. Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ Ø¯Ø±: {channel.next_check_time.strftime('%Y-%m-%d %H:%M:%S UTC')}. ")
        
        # Ù„Ø§Ú¯ INFO Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø­Ø°Ù Ø´ÙˆØ¯ ÛŒØ§ Ø¨Ù‡ DEBUG ØªØºÛŒÛŒØ± ÛŒØ§Ø¨Ø¯
        # logger.info(f"Ù¾Ø§ÛŒØ§Ù† ÙˆØ§Ú©Ø´ÛŒ Ø§Ø² Ù…Ù†Ø¨Ø¹: '{channel.url}'. Ù…Ø¬Ù…ÙˆØ¹ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡: {len(current_channel_valid_processed_configs)}.")
        return current_channel_valid_processed_configs

    def process_config(self, config_string: str, channel: ChannelConfig) -> Optional[Dict[str, str]]:
        """
        ÛŒÚ© Ú©Ø§Ù†ÙÛŒÚ¯ Ø±Ø§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯: Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒØŒ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒØŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒØŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…ØŒ
        Ùˆ Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ú†Ù… Ùˆ Ú©Ø´ÙˆØ±.
        """
        
        if not config_string:
            logger.debug("Ø±Ø´ØªÙ‡ Ú©Ø§Ù†ÙÛŒÚ¯ ÙˆØ±ÙˆØ¯ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
            return None

        # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±ÙˆØªÚ©Ù„ Hysteria2 Ùˆ Hysteria 1
        if config_string.startswith('hy2://'):
            config_string = self.validator.normalize_hysteria2_protocol(config_string)
            logger.debug(f"Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ 'hy2://' Ø¨Ù‡ 'hysteria2://' Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯: '{config_string[:min(len(config_string), 50)]}...'")
        elif config_string.startswith('hy1://'):
            config_string = config_string.replace('hy1://', 'hysteria://', 1) # ØªØ¨Ø¯ÛŒÙ„ alias Ø¨Ù‡ Ù¾Ø±ÙˆØªÚ©Ù„ Ø§ØµÙ„ÛŒ
            logger.debug(f"Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ 'hy1://' Ø¨Ù‡ 'hysteria://' Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯: '{config_string[:min(len(config_string), 50)]}...'")
            
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø² Ù…Ø´Ø®ØµØ§Øª Ø®ÙˆØ¯ Ú©Ø§Ù†ÙÛŒÚ¯
        discovered_channels_from_config = self.validator.extract_telegram_channels_from_config(config_string)
        for new_channel_url in discovered_channels_from_config:
            self.add_new_telegram_channel(new_channel_url)
            logger.debug(f"Ù„ÛŒÙ†Ú© Ú©Ø§Ù†Ø§Ù„ ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø² Ù…Ø´Ø®ØµØ§Øª Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: '{new_channel_url}'.")

        flag = "ğŸ³ï¸"
        country = "Unknown"
        actual_protocol = None

        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù¾Ø±ÙˆØªÚ©Ù„ Ø§ØµÙ„ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯
        for protocol_prefix in self.config.SUPPORTED_PROTOCOLS:
            aliases = self.config.SUPPORTED_PROTOCOLS[protocol_prefix].get('aliases', [])
            protocol_match = False
            
            if config_string.startswith(protocol_prefix):
                protocol_match = True
                actual_protocol = protocol_prefix
            else:
                for alias in aliases:
                    if config_string.startswith(alias):
                        protocol_match = True
                        config_string = config_string.replace(alias, protocol_prefix, 1) # Ø¬Ø§ÛŒÚ¯Ø²ÛŒØ³ÛŒ alias Ø¨Ø§ Ù¾Ø±ÙˆØªÚ©Ù„ Ø§ØµÙ„ÛŒ
                        actual_protocol = protocol_prefix
                        break
                        
            if protocol_match:
                # Ø§Ú¯Ø± Ù¾Ø±ÙˆØªÚ©Ù„ ÙØ¹Ø§Ù„ Ù†ÛŒØ³ØªØŒ Ú©Ø§Ù†ÙÛŒÚ¯ Ø±Ø§ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±ÛŒØ¯
                if not self.config.is_protocol_enabled(actual_protocol):
                    logger.debug(f"Ù¾Ø±ÙˆØªÚ©Ù„ '{actual_protocol}' ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª. Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: '{config_string[:min(len(config_string), 50)]}...'.")
                    return None 
                
                # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø®Ø§Øµ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ (VMess Ùˆ SSR)
                if actual_protocol == "vmess://":
                    config_string = self.validator.clean_vmess_config(config_string)
                    logger.debug(f"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ VMess: '{config_string[:min(len(config_string), 50)]}...'")
                elif actual_protocol == "ssr://":
                    config_string = self.validator.clean_ssr_config(config_string)
                    logger.debug(f"Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ SSR: '{config_string[:min(len(config_string), 50)]}...'")
                
                # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ (Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù†Ø§Ù…Ø±Ø¦ÛŒØŒ Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ùˆ ÙØ¶Ø§Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ)
                clean_config = self.validator.clean_config(config_string)
                
                # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ù¾Ø±ÙˆØªÚ©Ù„ Ø®Ø§Øµ
                if self.validator.validate_protocol_config(clean_config, actual_protocol):
                    canonical_id = self.validator.get_canonical_id(clean_config, actual_protocol)
                    
                    if canonical_id is None:
                        logger.debug(f"Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ù†ÙˆÙ†ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ '{actual_protocol}' ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯. Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: '{clean_config[:min(len(clean_config), 50)]}...'.")
                        return None
                        
                    with self._lock: # Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² seen_configs Ø¯Ø± Ù…Ø­ÛŒØ· Ù‡Ù…Ø²Ù…Ø§Ù†
                        if canonical_id not in self.seen_configs:
                            server_address = self.validator.get_server_address(clean_config, actual_protocol)
                            if server_address:
                                flag, country = self.get_location(server_address)
                                logger.debug(f"Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¨Ø±Ø§ÛŒ '{server_address}' ÛŒØ§ÙØª Ø´Ø¯: {flag} {country}")
                        
                            channel.metrics.valid_configs += 1
                            channel.metrics.protocol_counts[actual_protocol] = channel.metrics.protocol_counts.get(actual_protocol, 0) + 1
                            
                            self.seen_configs.add(canonical_id) 
                            self.protocol_counts[actual_protocol] += 1
                            logger.debug(f"Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ '{actual_protocol}' ÛŒØ§ÙØª Ø´Ø¯: '{clean_config[:min(len(clean_config), 50)]}...' (ID: {canonical_id[:min(len(canonical_id), 20)]}...).")
                            
                            return {
                                'config': clean_config, 
                                'protocol': actual_protocol,
                                'flag': flag,
                                'country': country,
                                'canonical_id': canonical_id 
                            }
                        else:
                            logger.info(f"Ú©Ø§Ù†ÙÛŒÚ¯ ØªÚ©Ø±Ø§Ø±ÛŒ '{actual_protocol}' Ø¨Ø§ Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ù†ÙˆÙ†ÛŒ {canonical_id[:min(len(canonical_id), 20)]}... Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯: '{clean_config[:min(len(clean_config), 50)]}...'.")
                else:
                    logger.debug(f"Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù¾Ø±ÙˆØªÚ©Ù„ '{actual_protocol}' Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯ '{clean_config[:min(len(clean_config), 50)]}...' Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯. Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
                break 
                
        logger.debug(f"Ú©Ø§Ù†ÙÛŒÚ¯ '{config_string[:min(len(config_string), 50)]}...' Ø¨Ø§ Ù‡ÛŒÚ† Ù¾Ø±ÙˆØªÚ©Ù„ ÙØ¹Ø§Ù„ ÛŒØ§ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù…Ø·Ø§Ø¨Ù‚Øª Ù†Ø¯Ø§Ø´Øª. Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
        return None

    def extract_date_from_message(self, message) -> Optional[datetime]:
        """
        ØªØ§Ø±ÛŒØ® Ùˆ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ´Ø§Ø± Ù¾ÛŒØ§Ù… Ø±Ø§ Ø§Ø² Ø¹Ù†ØµØ± <time> Ø¯Ø± HTML Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        """
        try:
            time_element = message.find_parent('div', class_='tgme_widget_message').find('time')
            if time_element and 'datetime' in time_element.attrs:
                return datetime.fromisoformat(time_element['datetime'].replace('Z', '+00:00'))
        except Exception as e:
            logger.debug(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ø§Ø² Ù¾ÛŒØ§Ù…: {str(e)}")
            pass
        return None

    def is_config_valid(self, config_text: str, date: Optional[datetime]) -> bool:
        """
        Ø¨Ø±Ø±Ø³ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ø¢ÛŒØ§ ØªØ§Ø±ÛŒØ® Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú©Ø§ÙÛŒ Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª (Ø·Ø¨Ù‚ MAX_CONFIG_AGE_DAYS).
        """
        if not date:
            logger.debug("ØªØ§Ø±ÛŒØ® Ú©Ø§Ù†ÙÛŒÚ¯ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªØŒ Ù…Ø¹ØªØ¨Ø± ÙØ±Ø¶ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            return True
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=self.config.MAX_CONFIG_AGE_DAYS)
        if date >= cutoff_date:
            return True
        else:
            logger.debug(f"Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨ÙˆØ¯Ù† ØªØ§Ø±ÛŒØ® (ØªØ§Ø±ÛŒØ®: {date}) Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
            return False

    def balance_protocols(self, configs: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø±ÙˆØªÚ©Ù„ Ø³Ø§Ø²Ù…Ø§Ù†Ø¯Ù‡ÛŒ Ùˆ Ù…ØªØ¹Ø§Ø¯Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ ØªÙˆØ²ÛŒØ¹ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯.
        Ø§ÛŒÙ† Ù…ØªØ¯ ØªØ¶Ù…ÛŒÙ† Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù¾Ø±ÙˆØªÚ©Ù„ Ø§Ø² "max_configs" ØªØ¹ÛŒÛŒÙ† Ø´Ø¯Ù‡
        Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ù¾Ø±ÙˆØªÚ©Ù„) ØªØ¬Ø§ÙˆØ² Ù†Ú©Ù†Ø¯.
        """
        logger.info("Ø´Ø±ÙˆØ¹ ØªÙˆØ§Ø²Ù† Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§...")
        protocol_configs: Dict[str, List[Dict[str, str]]] = {p: [] for p in self.config.SUPPORTED_PROTOCOLS}
        for config_dict in configs:
            protocol = config_dict['protocol']
            if protocol.startswith('hy2://'):
                protocol = 'hysteria2://'
            elif protocol.startswith('hy1://'):
                protocol = 'hysteria://'
            
            if protocol in protocol_configs:
                protocol_configs[protocol].append(config_dict)
            else:
                logger.warning(f"Ù¾Ø±ÙˆØªÚ©Ù„ '{protocol}' Ø¯Ø± Ù„ÛŒØ³Øª Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙˆØ§Ø²Ù† ÛŒØ§ÙØª Ù†Ø´Ø¯. Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.")

        total_configs = sum(len(configs_list) for configs_list in protocol_configs.values())
        if total_configs == 0:
            logger.info("Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ ØªÙˆØ§Ø²Ù† Ù¾Ø±ÙˆØªÚ©Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
            return []
            
        balanced_configs: List[Dict[str, str]] = []
        sorted_protocols = sorted(
            protocol_configs.items(),
            key=lambda x: (
                self.config.SUPPORTED_PROTOCOLS.get(x[0], {"priority": 999})["priority"], 
                len(x[1])
            ),
            reverse=True
        )
        logger.info(f"Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ§Ø²Ù† {total_configs} Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ {len(sorted_protocols)} Ù¾Ø±ÙˆØªÚ©Ù„ Ù…Ø±ØªØ¨ Ø´Ø¯Ù‡...")
        
        for protocol, protocol_config_list in sorted_protocols:
            protocol_info = self.config.SUPPORTED_PROTOCOLS.get(protocol)
            if not protocol_info:
                logger.warning(f"Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±ÙˆØªÚ©Ù„ '{protocol}' ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
                continue

            if len(protocol_config_list) >= protocol_info["min_configs"]:
                num_to_add = min(
                    protocol_info["max_configs"],  
                    len(protocol_config_list)     
                )
                balanced_configs.extend(protocol_config_list[:num_to_add])
                logger.info(f"Ù¾Ø±ÙˆØªÚ©Ù„ '{protocol}': {num_to_add} Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯ (Ø§Ø² {len(protocol_config_list)} Ù…ÙˆØ¬ÙˆØ¯ØŒ Ø­Ø¯Ø§Ú©Ø«Ø± Ù…Ø¬Ø§Ø²: {protocol_info['max_configs']}).")
            elif protocol_info["flexible_max"] and len(protocol_config_list) > 0:
                balanced_configs.extend(protocol_config_list)
                logger.info(f"Ù¾Ø±ÙˆØªÚ©Ù„ '{protocol}': {len(protocol_config_list)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯ (Ø­Ø§Ù„Øª flexible_max).")
            else:
                logger.debug(f"Ù¾Ø±ÙˆØªÚ©Ù„ '{protocol}': ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ú©Ø§ÙÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ ({len(protocol_config_list)}).")
        
        logger.info(f"ØªÙˆØ§Ø²Ù† Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ Ú©Ø§Ù…Ù„ Ø´Ø¯. Ù…Ø¬Ù…ÙˆØ¹Ø§Ù‹ {len(balanced_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ.")
        return balanced_configs

    def fetch_all_configs(self) -> List[Dict[str, str]]:
        """
        ÙˆØ§Ú©Ø´ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø§Ø² ØªÙ…Ø§Ù… Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ùˆ Ø§Ø¹Ù…Ø§Ù„ ØªÙˆØ§Ø²Ù† Ù¾Ø±ÙˆØªÚ©Ù„.
        Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø¯Ø± Ø­Ø§Ù„Øª Smart Retry Ù‡Ø³ØªÙ†Ø¯ØŒ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ ØªØ§ Ø²Ù…Ø§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒâ€ŒØ´Ø§Ù† ÙØ±Ø§ Ø±Ø³Ø¯.
        """
        all_configs: List[Dict[str, str]] = []
        
        channels_to_process = []
        now = datetime.now(timezone.utc)
        
        logger.info(f"Ø¯Ø± Ø­Ø§Ù„ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´. Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ: {now.strftime('%Y-%m-%d %H:%M:%S UTC')}.")
        for channel in list(self.config.SOURCE_URLS):
            if not channel.enabled:
                logger.debug(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª Ùˆ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
                continue
            if channel.next_check_time and channel.next_check_time > now:
                logger.info(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯. Ø²Ù…Ø§Ù† Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ: {channel.next_check_time.strftime('%Y-%m-%d %H:%M:%S UTC')}.")
                continue
            channels_to_process.append(channel)
            logger.debug(f"Ú©Ø§Ù†Ø§Ù„ '{channel.url}' Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯.")
        
        total_channels_to_process = len(channels_to_process)
        if total_channels_to_process == 0:
            logger.info("Ù‡ÛŒÚ† Ú©Ø§Ù†Ø§Ù„ ÙØ¹Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯ (ÛŒØ§ Ù‡Ù…Ù‡ Ø¯Ø± Ø­Ø§Ù„Øª ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù‡Ø³ØªÙ†Ø¯). ÙØ±Ø¢ÛŒÙ†Ø¯ ÙˆØ§Ú©Ø´ÛŒ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
            return []

        logger.info(f"Ø´Ø±ÙˆØ¹ ÙˆØ§Ú©Ø´ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø§Ø² {total_channels_to_process} Ú©Ø§Ù†Ø§Ù„ ÙØ¹Ø§Ù„ Ø¨Ù‡ ØµÙˆØ±Øª Ù‡Ù…Ø²Ù…Ø§Ù† (Parallel Fetching Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª).")
        
        # **ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡**: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ThreadPoolExecutor Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ Ù…ÙˆØ§Ø²ÛŒ
        # max_workers Ø±Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ CPUÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ ÛŒØ§ Ù¾Ù‡Ù†Ø§ÛŒ Ø¨Ø§Ù†Ø¯ Ø´Ø¨Ú©Ù‡ ØªÙ†Ø¸ÛŒÙ… Ú©Ø±Ø¯.
        # ØªØ¹Ø¯Ø§Ø¯ 10 ØªØ§Ù¾ÛŒÚ© Ø¨Ø±Ø§ÛŒ ØªØ¹Ø§Ø¯Ù„ Ø¨ÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ Ø´Ø¯Ù† IP Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³Øª.
        with concurrent.futures.ThreadPoolExecutor(max_workers=min(10, total_channels_to_process + 1)) as executor:
            # Ø§Ø±Ø³Ø§Ù„ Ù‡Ø± Ú©Ø§Ù†Ø§Ù„ Ø¨Ù‡ ÛŒÚ© Thread Ø¨Ø±Ø§ÛŒ ÙˆØ§Ú©Ø´ÛŒ
            futures = {executor.submit(self.fetch_configs_from_source, channel): channel for channel in channels_to_process}
            
            # **Ø¬Ø¯ÛŒØ¯**: Ù¾ÛŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒØ´Ø±ÙØª Ùˆ Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ù†ØªØ§ÛŒØ¬ Ù‡Ø± Ú©Ø§Ù†Ø§Ù„ Ø¨Ù‡ Ù…Ø­Ø¶ ØªÚ©Ù…ÛŒÙ„
            processed_channels_count = 0
            for future in concurrent.futures.as_completed(futures):
                channel_processed = futures[future]
                processed_channels_count += 1
                progress_percentage = (processed_channels_count / total_channels_to_process) * 100
                
                try:
                    result_list = future.result() # Ø¯Ø±ÛŒØ§ÙØª Ù†ØªÛŒØ¬Ù‡ (Ù„ÛŒØ³Øª Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡)
                    all_configs.extend(result_list)
                    logger.info(f"Ù¾ÛŒØ´Ø±ÙØª: {progress_percentage:.2f}% ({processed_channels_count}/{total_channels_to_process}) - Ú©Ø§Ù†Ø§Ù„ '{channel_processed.url}' Ø¨Ø§ {len(result_list)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯. (Ú©Ù„ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡ ØªØ§Ú©Ù†ÙˆÙ†: {len(all_configs)})")
                except Exception as exc:
                    logger.error(f"Ù¾ÛŒØ´Ø±ÙØª: {progress_percentage:.2f}% ({processed_channels_count}/{total_channels_to_process}) - Ú©Ø§Ù†Ø§Ù„ '{channel_processed.url}' Ø¯Ø± Ø­ÛŒÙ† ÙˆØ§Ú©Ø´ÛŒ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯: {exc}", exc_info=True)


        if all_configs:
            logger.info(f"ÙˆØ§Ú©Ø´ÛŒ Ø§Ø² Ù‡Ù…Ù‡ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯. Ù…Ø¬Ù…ÙˆØ¹Ø§Ù‹ {len(all_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ø®Ø§Ù… Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯.")
            
            # **ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡**: Unique Ú©Ø±Ø¯Ù† Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ù†ÙˆÙ†ÛŒ
            final_unique_configs_list = []
            seen_canonical_ids_for_final_list = set()
            for cfg_dict in all_configs:
                canonical_id = cfg_dict.get('canonical_id') 
                if canonical_id and canonical_id not in seen_canonical_ids_for_final_list:
                    seen_canonical_ids_for_final_list.add(canonical_id)
                    final_unique_configs_list.append(cfg_dict)

            logger.info(f"Ù¾Ø³ Ø§Ø² Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒØŒ {len(final_unique_configs_list)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯.")
            all_configs = self.balance_protocols(sorted(final_unique_configs_list, key=lambda x: x['config']))
            logger.info(f"ÙØ±Ø¢ÛŒÙ†Ø¯ ÙˆØ§Ú©Ø´ÛŒ Ùˆ ØªÙˆØ§Ø²Ù† Ú©Ø§Ù…Ù„ Ø´Ø¯. {len(all_configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø°Ø®ÛŒØ±Ù‡.")
            return all_configs
        else:
            logger.warning("Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ù¾Ø³ Ø§Ø² ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÛŒØ§ÙØª Ù†Ø´Ø¯!")
            return []

    # --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ú©Ù‡ Ø¨Ù‡ Ù…ØªØ¯Ù‡Ø§ÛŒ Ú©Ù„Ø§Ø³ ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯ ---
    def _save_base64_file(self, file_path: str, content: str):
        """ÛŒÚ© Ù…Ø­ØªÙˆØ§ Ø±Ø§ Base64 Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
        try:
            encoded_content = base64.b64encode(content.encode('utf-8')).decode('utf-8')
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(encoded_content)
            logger.info(f"Ù…Ø­ØªÙˆØ§ÛŒ Base64 Ø´Ø¯Ù‡ Ø¯Ø± '{file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Base64 Ø´Ø¯Ù‡ '{file_path}': {str(e)}")

    def save_configs(self, configs: List[Dict[str, str]]):
        """
        Ø°Ø®ÛŒØ±Ù‡ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø¯Ø± Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡ Ø¬Ø¯ÛŒØ¯.
        Ø­Ø§Ù„Ø§ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø´Ø§Ù…Ù„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø±Ú†Ù… Ùˆ Ú©Ø´ÙˆØ± Ù‡Ø³ØªÙ†Ø¯.
        """
        logger.info("Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒâ€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§...")
        os.makedirs(self.config.TEXT_OUTPUT_DIR, exist_ok=True)
        os.makedirs(self.config.BASE64_OUTPUT_DIR, exist_ok=True)
        os.makedirs(self.config.SINGBOX_OUTPUT_DIR, exist_ok=True)

        header = """//profile-title: base64:8J+RvUFub255bW91cy3wnZWP
//profile-update-interval: 1
//subscription-userinfo: upload=0; download=0; total=10737418240000000; expire=2546249531
//support-url: https://t.me/BXAMbot
//profile-web-page-url: https://github.com/4n0nymou3

"""
    
        full_text_lines = []
        for cfg_dict in configs:
            full_text_lines.append(f"{cfg_dict['flag']} {cfg_dict['country']} {cfg_dict['config']}")
        full_text_content = header + '\n\n'.join(full_text_lines) + '\n'

        full_file_path = os.path.join(self.config.TEXT_OUTPUT_DIR, 'proxy_configs.txt')
        try:
            with open(full_file_path, 'w', encoding='utf-8') as f:
                f.write(full_text_content)
            logger.info(f"Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª {len(configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± '{full_file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ Ú©Ø§Ù†ÙÛŒÚ¯: {str(e)}")

        base64_full_file_path = os.path.join(self.config.BASE64_OUTPUT_DIR, "proxy_configs_base64.txt")
        self._save_base64_file(base64_full_file_path, full_text_content)

        protocol_configs_separated: Dict[str, List[Dict[str, str]]] = {p: [] for p in self.config.SUPPORTED_PROTOCOLS}
        for cfg_dict in configs:
            protocol_full_name = cfg_dict['protocol']
            if protocol_full_name.startswith('hy2://'):
                protocol_full_name = 'hysteria2://'
            elif protocol_full_name.startswith('hy1://'):
                protocol_full_name = 'hysteria://'
            
            if protocol_full_name in protocol_configs_separated:
                 protocol_configs_separated[protocol_full_name].append(cfg_dict)
            else:
                logger.warning(f"Ù¾Ø±ÙˆØªÚ©Ù„ '{protocol_full_name}' Ø¯Ø± Ù„ÛŒØ³Øª Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªÙÚ©ÛŒÚ© ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        for protocol_full_name, cfg_list_of_dicts in protocol_configs_separated.items():
            if not cfg_list_of_dicts:
                continue

            protocol_name = protocol_full_name.replace('://', '')
            protocol_text_lines = []
            for cfg_dict in cfg_list_of_dicts:
                 protocol_text_lines.append(f"{cfg_dict['flag']} {cfg_dict['country']} {cfg_dict['config']}")
            protocol_text_content = header + '\n\n'.join(protocol_text_lines) + '\n'

            protocol_file_name = f"{protocol_name}.txt"
            protocol_file_path = os.path.join(self.config.TEXT_OUTPUT_DIR, protocol_file_name)
            try:
                with open(protocol_file_path, 'w', encoding='utf-8') as f:
                    f.write(protocol_text_content)
                logger.info(f"Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª {len(cfg_list_of_dicts)} Ú©Ø§Ù†ÙÛŒÚ¯ '{protocol_name}' Ø¯Ø± '{protocol_file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
            except Exception as e:
                logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ '{protocol_name}' Ú©Ø§Ù†ÙÛŒÚ¯: {str(e)}")

            base64_protocol_file_name = f"{protocol_name}_base64.txt"
            base64_protocol_file_path = os.path.join(self.config.BASE64_OUTPUT_DIR, base64_protocol_file_name)
            self._save_base64_file(base64_protocol_file_path, protocol_text_content)

    def save_channel_stats(self):
        """
        Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±Ù‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡ Ø§Ø² Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON.
        """
        logger.info("Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±Ù‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§...")
        try:
            stats = {
                'timestamp': datetime.now(timezone.utc).isoformat(),
                'channels': []
            }
            
            for channel in self.config.SOURCE_URLS: 
                channel_stats = {
                    'url': channel.url,
                    'enabled': channel.enabled,
                    'metrics': {
                        'total_configs': channel.metrics.total_configs,
                        'valid_configs': channel.metrics.valid_configs,
                        'unique_configs': channel.metrics.unique_configs,
                        'avg_response_time': round(channel.metrics.avg_response_time, 2),
                        'success_count': channel.metrics.success_count,
                        'fail_count': channel.metrics.fail_count,
                        'overall_score': round(channel.metrics.overall_score, 2),
                        'last_success': channel.metrics.last_success_time.replace(tzinfo=timezone.utc).isoformat() if channel.metrics.last_success_time else None,
                        'protocol_counts': channel.metrics.protocol_counts
                    },
                    'retry_level': channel.retry_level,
                    'next_check': channel.next_check_time.isoformat() if channel.next_check_time else None
                }
                stats['channels'].append(channel_stats)
                
            os.makedirs(os.path.dirname(self.config.STATS_FILE), exist_ok=True)
            with open(self.config.STATS_FILE, 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
                
            logger.info(f"Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„ Ø¯Ø± '{self.config.STATS_FILE}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¢Ù…Ø§Ø±Ù‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„: {str(e)}")

    def generate_channel_status_report(self):
        """
        Ú¯Ø²Ø§Ø±Ø´ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ ØªÙ…Ø§Ù…ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø¨Ø¹ (Ø´Ø§Ù…Ù„ Ú©Ø´Ù Ø´Ø¯Ù‡â€ŒÙ‡Ø§) Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ù…ØªÛŒØ§Ø² Ú©Ù„ÛŒ Ù…Ø±ØªØ¨ Ø´Ø¯Ù‡ Ùˆ Ù…ÙˆØ§Ø±Ø¯ Ø¬Ø¯ÛŒØ¯ Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
        """
        logger.info("Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§...")
        report_file_path = os.path.join(self.config.OUTPUT_DIR, 'channel_status_report.md')
        
        report_content = [
            f"# Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø§Ú©Ø³ÛŒ ({datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')})",
            "",
            "Ø§ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² ÙˆØ¶Ø¹ÛŒØª Ø¢Ø®Ø±ÛŒÙ† ÙˆØ§Ú©Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ù†Ø§Ù„ Ù…Ù†Ø¨Ø¹ Ø§Ø³Øª. Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙˆÙ„ÛŒØ¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.",
            "",
            "## ÙˆØ¶Ø¹ÛŒØª Ú©Ù„ÛŒ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§",
            ""
        ]

        channels_for_report = list(self.config.SOURCE_URLS)

        processed_channels = []
        newly_discovered_channels = []
        
        for channel in channels_for_report:
            normalized_url = self.config._normalize_url(channel.url)
            is_newly_discovered_current_run = normalized_url not in self.initial_user_settings_urls and \
                                             normalized_url not in self.previous_stats_urls
            
            if is_newly_discovered_current_run:
                newly_discovered_channels.append(channel)
            else:
                processed_channels.append(channel)

        processed_channels.sort(key=lambda c: c.metrics.overall_score, reverse=True)
        
        newly_discovered_channels.sort(key=lambda c: c.url)

        sorted_channels_for_report = processed_channels + newly_discovered_channels

        for channel in sorted_channels_for_report:
            normalized_url = self.config._normalize_url(channel.url)
            is_newly_discovered_current_run = normalized_url not in self.initial_user_settings_urls and \
                                             normalized_url not in self.previous_stats_urls

            status_line = f"- **URL**: `{channel.url}`"
            if is_newly_discovered_current_run:
                status_line += " **(Ø¬Ø¯ÛŒØ¯ Ú©Ø´Ù Ø´Ø¯Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø§Ø¬Ø±Ø§!)**"
            
            status_line += f"\n  - **ÙØ¹Ø§Ù„**: {'âœ… Ø¨Ù„Ù‡' if channel.enabled else 'âŒ Ø®ÛŒØ±'}"
            status_line += f"\n  - **Ø¢Ø®Ø±ÛŒÙ† Ø§Ù…ØªÛŒØ§Ø²**: `{channel.metrics.overall_score:.2f}`"
            status_line += f"\n  - **ÙˆØ¶Ø¹ÛŒØª ÙˆØ§Ú©Ø´ÛŒ**: Ù…ÙˆÙÙ‚: `{channel.metrics.success_count}` | Ù†Ø§Ù…ÙˆÙÙ‚: `{channel.metrics.fail_count}`"
            status_line += f"\n  - **Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù…Ø¹ØªØ¨Ø± (Ø¢Ø®Ø±ÛŒÙ† ÙˆØ§Ú©Ø´ÛŒ)**: `{channel.metrics.valid_configs}`"
            
            protocol_counts_str = ", ".join([f"{p.replace('://', '')}: {count}" for p, count in channel.metrics.protocol_counts.items() if count > 0])
            if protocol_counts_str:
                status_line += f"\n  - **Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯**: {protocol_counts_str}"
            else:
                status_line += f"\n  - **Ù¾Ø±ÙˆØªÚ©Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯**: (Ù‡ÛŒÚ†)"

            if channel.next_check_time:
                status_line += f"\n  - **ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯**: Ø³Ø·Ø­ `{channel.retry_level}` | Ø¨Ø±Ø±Ø³ÛŒ Ø¨Ø¹Ø¯ÛŒ: `{channel.next_check_time.strftime('%Y-%m-%d %H:%M:%S UTC')}`"
            else:
                status_line += f"\n  - **ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ù‡ÙˆØ´Ù…Ù†Ø¯**: Ø¹Ø§Ø¯ÛŒ (Ø¨Ø§Ø²Ù†Ø´Ø§Ù†ÛŒ Ø´Ø¯Ù‡)"

            report_content.append(status_line)
            report_content.append("") 

        try:
            os.makedirs(os.path.dirname(report_file_path), exist_ok=True)
            with open(report_file_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(report_content))
            logger.info(f"Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± '{report_file_path}' Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ ÙˆØ¶Ø¹ÛŒØª Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§: {str(e)}")


def main():
    """
    ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ ÙØ±Ø¢ÛŒÙ†Ø¯ ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§.
    """
    try:
        logger.info("Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ ÙˆØ§Ú©Ø´ÛŒ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§...")
        config = ProxyConfig() 
        fetcher = ConfigFetcher(config) 
        
        configs = fetcher.fetch_all_configs()
        
        if configs:
            fetcher.save_configs(configs)
            logger.info(f"ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')} Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ù…Ø¬Ù…ÙˆØ¹Ø§Ù‹ {len(configs)} Ú©Ø§Ù†ÙÛŒÚ¯ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯.")
            
            logger.info("ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø±ÙˆØªÚ©Ù„:")
            for protocol, count in fetcher.protocol_counts.items():
                logger.info(f"  {protocol}: {count} Ú©Ø§Ù†ÙÛŒÚ¯")
        else:
            logger.error("Ù‡ÛŒÚ† Ú©Ø§Ù†ÙÛŒÚ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯ Ùˆ Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ÛŒ ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯!")
            
        fetcher.save_channel_stats()
        logger.info("Ø¢Ù…Ø§Ø± Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

        fetcher.generate_channel_status_report()
            
    except Exception as e:
        logger.critical(f"Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ: {str(e)}", exc_info=True)

if __name__ == '__main__':
    main()

